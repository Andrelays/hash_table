# Хэш Таблицы

Проект исследования и оптимизаций хэш таблиц.

## Оглавление

- [Хэш Таблицы](#хэш-таблицы)
  - [Оглавление](#оглавление)
  - [Описание](#описание)
  - [Первая часть](#первая-часть)
    - [Функции](#функции)
    - [Гистограммы](#гистограммы)
    - [Однородность](#однородность)
  - [Вторая часть](#вторая-часть)
    - [Оптимизации](#оптимизации)
  - [Итоги и выводы](#итоги-и-выводы)

## Описание

В этой работе я исследовал различные хэш-функции на однородность и исследовал влияние разных оптимизаций на хэш таблицы. В своем исследовании я использовал простую реализацию хэш-таблицы с двусвязными списками, которые отвечают за обработку коллизий.

В первой части я брал различные функции и исследовал их на однородное распределение. База данных состоит из слов произведения: [Mikhail Bulgakov. The Master and Margarita](https://web.archive.org/web/20110606093139/http://lib.ru/BULGAKOW/master97_engl.txt).

```
int               hash_table_ctor   (hash_table *, size_t, size_t (*hash_function)(ht_key_t, ht_value_t));
int               hash_table_add    (hash_table *, ht_key_t, ht_value_t);
int               hash_table_dtor   (hash_table *);
TYPE_ELEMENT_LIST hash_table_search (hash_table *, ht_key_t, ht_value_t);
```

Во второй части я работал с профилировщиком и оптимизировал скорость работы хэш таблиц с помощью встройки, выравниваний, ассемблерных вставок и SIMD инструкций.

## Первая часть
Первым объектом нашего исследования будут хэш-функции. Я начну с простых (наивных) хэш-функций, а затем перейду к более сложным.

### Функции:

1. Хэш возвращает 0.
2. Хэш возвращает ascii код 1 буквы слова.
3. Хэш возвращает длину слова.
4. Хэш возвращает сумму ascii кодов слова.
5. Хэщ возвращает (сумму букв)/(длину слова).
6. ROL хэш. `hash[i] = ROL(hash[i-1]) xor str[i]`
7. ROR хэш. `hash[i] = ROR(hash[i-1]) xor str[i]`
8. [Elf Хэш](https://en.wikipedia.org/wiki/PJW_hash_function)
9. [CRC32 Хэш](https://ru.wikibooks.org/wiki/Реализации_алгоритмов/Циклический_избыточный_код).

Для изучения распределения я строил гистограммы `КоличествоКоллизий(ЗначениеХэша)`. Диаграммы показывают распределение числа коллизий по значениям хэш-функции, в некоторых из них есть пики, которые влияют на скорость работы хэш таблицы(линейный поиску по списку).

Также размер хэш таблицы фиксирован и является простым числом.

Теория по хэш таблицам бралась из [Википедии](https://en.wikipedia.org/wiki/Hash_function)

### Гистограммы

<p> <strong>

В 1-4 представлены простые хэш-функции, которые не используются в реальных проектах. У них нет одинакового размера, они рассматриваются в учебных целях.

В 5-9 представлены сложные хэш-функции, которые применяются в разработке. Их я сравнивал отдельно с одинаковым размером таблицы

1. <U> 0 Hash </U>: Размер: 7, макс. коллизия: 11550.
<img src="https://github.com/Andrelays/hash_table/blob/main/pictures/output1.png?raw=true" width = 100%>

2. <U> First Letter Hash </U>: Размер: 127, макс. коллизия: 1334.
<img src="https://github.com/Andrelays/hash_table/blob/main/pictures/output2.png?raw=true" width = 100%>

3. <U> Length Word Hash </U>: Размер 31, макс. коллизия: 1908.
<img src="https://github.com/Andrelays/hash_table/blob/main/pictures/output3.png?raw=true" width = 100%>

4. <U> Sum of letters Hash </U>: Размер 1501, макс. коллизия: 48.
<img src="https://github.com/Andrelays/hash_table/blob/main/pictures/output4.png?raw=true" width = 100%>

5. <U> (Sum of letters)/Length Hash </U>: Размер 179, макс. коллизия: 1615.
<img src="https://github.com/Andrelays/hash_table/blob/main/pictures/output5.png?raw=true" width = 100%>

6. <U> ROR Hash </U>: Размер 6007, макс. коллизия: 20.
<img src="https://github.com/Andrelays/hash_table/blob/main/pictures/output6.png?raw=true" width = 100%>

7. <U> ROL Hash </U>: Размер 6007, макс. коллизия: 11.
<img src="https://github.com/Andrelays/hash_table/blob/main/pictures/output7.png?raw=true" width = 100%>

8. <U> Elf Hash </U>: Размер 6007, макс. коллизия: 8.
<img src="https://github.com/Andrelays/hash_table/blob/main/pictures/output8.png?raw=true" width = 100%>

9.  <U> CRC32 Hash </U>: Размер 6007, макс. коллизия: 9.
<img src="https://github.com/Andrelays/hash_table/blob/main/pictures/output9.png?raw=true" width = 100%>

</strong></p>

### Однородность

Для численного описания хэш-функций я буду использовать дисперсию:

$$\text{Var(X)} = \frac{1}{n}\sum_{i=1}^n(x_i - \mu)^2, $$
где $\mu$ - среднее значение:

$$
\mu = \frac{1}{n} \sum_{i = 1}^n x_i
$$

Идеальная хэш-функция распределяет слова равномерно, так что дисперсия приближается к нулю.

#### Таблица дисперсий:


|Название хэш-функции               |Var(x) - величина дисперсии      |
|:----------------------------------|:-------------------------------:|
|0 Hash                             | $$ 1.633 * 10^8 $$              |
|First Letter Hash                  | $$ 4.033 * 10^4 $$              |
|Length Word Hash                   | $$ 3.647 * 10^5 $$              |
|Sum of letters Hash                | $$ 9.636 * 10^1 $$              |
|(Sum of letters)/Length Hash       | $$ 6.491 * 10^4 $$              |
|ROR Hash                           | $$ 7.019 * 10^0 $$              |
|ROL Hash                           | $$ 2.523 * 10^0 $$              |
|Elf Hash                           | $$ 1.917 * 10^0 $$              |
|CRC32 Hash                         | $$ 1.861 * 10^0 $$              |

Лучшие функции в однородности стали CRC32, ElfHash и ROL Hash.

## Вторая часть

*Система:*

- Linux Mint 21.3 Cinnamon
- AMD Ryzen 9 7845HX with Radeon Graphics × 12
- CPU Temperature: 55-65 $^\circ C$, нет троттлинга
- GCC x86-64 -O3 -msse4.1 -msse4.2 -mavx2 -mavx

Я создал стресс тест: загружал в таблицу текст "Мастера и Маргариты" и с помощью функции `stress_test()` искал каждое слово из книги 512 раз и ещё 1 несуществующее 10000 раз.

Далее с помощью профилировщика я нашел узкие места, которые замедляли скорость работы таблицы и оптимизировал их.

В качестве профилировщика использовался [Perf](https://perf.wiki.kernel.org/index.php/Tutorial) & [Guide Perf](https://stackoverflow.com/questions/1777556/alternatives-to-gprof/10958510#10958510) и визуализировал с помощью [HotSpot](https://github.com/KDAB/hotspot).

**Консольная версия:**
<img src="https://github.com/khmelnitskiianton/HashTable/assets/142332024/ef78e3a1-ec0b-4a28-b44c-4fde2106eff2" width = 100%>

**HotSpot версия:**
<img src="https://github.com/khmelnitskiianton/HashTable/assets/142332024/6a564442-141e-4e42-bdbe-98ce62c61835" width = 100%>

**Анализирование профилировщика**: (Размер=6007, Хэш: CRC 32)

Я не оптимизировал функции инициализации `hash_table_init_item()` и `hash_table_ctor() / hash_table_dtor()`, потому что они специфичны и работают с файлами.

Поэтому узкие места это `hash_table_search()`, `find_elem_by_value()`, `crc32_hash`, `strcmp()`.

Время я измерял через функцию `__rdtsc()`.

Я измерял время всей программы, которая включает создание хэш таблицы, загрузка слов и стресс тест. Поэтому итоговые данные показывают изменение скорости работы программы в целом.

> Отдельно были тесты для только стресс теста, и ускорение не зависит от измерения времени всей программы или только функций поиска.

Первое контрольное время работы программы: $1.91 \cdot 10^6$ тиков.

> Из-за многих факторов длительность фрагмента кода измеренная в тиках не постоянна([Статья](https://habr.com/ru/companies/intel/articles/260113/)), поэтому разброс значение составляет $\pm 5$%. Во-первых, многопроцессорность и многоядерность, в системе с несколькими потоками, ядрами или процессорами у каждого из логических процессоров будет свой TSC. Во-вторых, Внеочередное исполнение (Out of Order Execution, OoO), процессор может исполнять машинные инструкции в порядке, отличном от использованного в программе, или даже параллельно (если они не зависят друг от друга), это означает, что исполнение rdtsc может быть задержано или, наоборот, выполнено раньше, чем того требует последовательный программный порядок. В-третьих, управление энергопотреблением, Процессор довольно значительную долю времени может быть приостановлен для экономии энергии (C-состояния), исполняя инструкции, он может использовать динамическое изменение частоты для экономии энергии (P-состояния) или наоборот, для максимизации производительности (Turbo-состояния).

### Оптимизации

0. **Оптимизация встройкой:**

Во-первых, Я решил сделать функции поиска встроенными, на вызов функций сравнения тратиться время, несмотря на то что блок кода мал. Поэтому я поместил функции поиска по списку и сравнение в `.h` и использовал `inline`.

> [GCC](https://microsin.net/programming/avr/gcc-inline-functions.html) не встраивает функции при отключенной оптимизации, поэтому нужно использовать атрибут `inline __attribute__((always_inline))`. Поэтому при работе с `-O0` GCC не будет встраивать ничего через обычный `inline` (Это видно из профилировщика).

Новое время стресс теста - $3.00 \cdot 10^6$ тиков. Встраивание дало прирост 20 % в скорости работы программы, так как были убраны множественные вызовы функций.

1. **STRCMP Оптимизация:**

После всех оптимизаций самый долгий процесс это `strcmp()`. Я использовал AVX инструкции.

В моих данных самое длинное слово размером 28 букв, поэтому я использовал 16 байтные вектора `__m128`.

```cpp
__m128i str1 = _mm_load_si128((const __m128i *) (val1.Key));
__m128i str2 = _mm_load_si128((const __m128i *) (val2.Key));
__m128i cmp  = _mm_cmpeq_epi8 (str1, str2);
int result   = _mm_movemask_epi8 (cmp);
return ((result == 0xFFFF) && (val1.Value == val2.Value));
```

> `_mm_load_si128()` работает быстрее других функций загрузки в вектор, но она требует выравнивания адреса по 16 байт, иначе это приведет к ошибке `load of misaligned address`-Ошибка сегментации.

Новое время - $1.89 \cdot 10^6$ тиков (прирост 13%)

1. **Оптимизация хэш-функции:**

Первая версия CRC32 использовала полином с помощью постоянного массива.

Вторая версия использовала встроенные функции SSE `_mm_crc32_u8 (crc, char)`, $2.73 \cdot 10^6$ тиков:

```cpp
size_t crc = 0xFFFFFFFFUL;
for (size_t i = 0; i < length; i++)
    crc = _mm_crc32_u8 (crc, str[i]);
return crc ^ 0xFFFFFFFFUL;
```

Я попробовал переписать его на ассемблере `asm()`:

```cpp
asm(
    ".intel_syntax noprefix                     \n"
    "   add     %[len], %[str]                  \n"
    "   mov     edx, 4294967295                 \n"
    ".for_loop:                                 \n"
    "   mov     %[crc], rdx                     \n"
    "   add     %[str], 1                       \n"
    "   crc32   %[crc], byte ptr [%[str]-1]     \n"
    "   mov     rdx, %[crc]                     \n"
    "   cmp     %[len], %[str]                  \n"
    "   jne     .for_loop                       \n"
    "   not     %[crc]                          \n"
    ".att_syntax noprefix                       \n"
    : [crc] "=r" (crc)
    : [str] "r"  (str), [len] "r"  (length)
);
```
Это было сделано в учебных целях. Нет разницы между написанием через `_mm_crc32_u8()` и `asm()`.

Также я попробовал использовать `_mm_crc32_u64()`:

```cpp
size_t crc = 0xFFFFFFFFUL;
crc = _mm_crc32_u64 (crc, *((uint64_t*) str));
crc = _mm_crc32_u64 (crc, *(((uint64_t*) str)+1));
return crc ^ 0xFFFFFFFFUL;
```

Первый результат был странным, время возросло в 2 раза. Это вызвано тем, что выравнивание играет важную роль в скорости работы, т.к. SIMD инструкции зависят от кэша и буфер который загружается в кэш зависит от адреса([Статья от Intel](https://habr.com/ru/companies/intel/articles/262933/))

> Лучшее время достигается при использовании `_mm_crc32_u64()` + `aligned_alloc()`, а не `_mm_crc32_u8()` + `calloc()`

Поэтому сначала я создал выравненный буфер и поместил туда все слова.
Я использовал `aligned_alloc(ALIGNING, bytes)` + `memset()` затем скопировал все слова.

Итоговое время стресс теста - $2.19 \cdot 10^6$ тиков (прирост 19 %)

> Я использовал выравнивание по 16 байт. Большее выравнивание не дает ускорения. Если использовать выравнивание по 8 байт и менее это приведет к задержкам, поэтому я подтвердил результаты статьи.

**Итоговый отчет Perf:**

<img src="https://github.com/khmelnitskiianton/HashTable/assets/142332024/32edd8e2-a6fe-408c-82b8-2c2eb8477ccd" width = 100%>

## Итоги и выводы

После всех оптимизаций я ускорил работу программы в  1.85x - 1.9x (погрешность)! Я добавил скорость к оптимизации компилятора GCC на `-O3` почти в 2 раза.

*Таблица результатов*:

|Оптимизация               |Тики ($10^6$)      |Ускорение(в сравнении с началом) |
|:-------------------------|:-----------------:|:-------------------------------:|
|Начало с `-O3`            | 1.91              |1.00x                            |
|Встройка                  | 3.01              |1.20x                            |
|Смена ElfHash на CRC32    | 2.73              |1.32x                            |
|Выравнивание              | 2.64              |1.36x                            |
|Векторизация CRC32        | 2.19              |1.64x                            |
|Векторизация `strcmp()`   | 1.89              |1.90x                            |

В этом проекте я исследовал хэш-функции, работал с профилировщиком(Perf & HotSpot), ищя узкие места в работе программы и устранял их с помощью оптимизаций таких как: встройка, выравнивание, SIMD инструкции, ассемблерные вставки.

$DedInsideCoeff = \frac{boost}{amount \space asm \space strings} \cdot 100 = \frac{190}{12} = 15.8$
